paths_config:
    data_file_path: 'data/train_data.mat' # The features files of the 136 recordings
    save_path: 'results/temp' # where to save the results
        
params_config:
    calculate: True # (if false then only tuning is happening)
    n_out: 1 # number of nodes at the las layer
    act_out: "linear" # activation function of the output layer
    loss_func: "mse" 
    metric: "mse"
    early_stopping: 
        eval: True
        patience: 20
    plot_TF: False # Do/dont plot the histogram of target score in train data (read_data.py)
    save_model: True # If to save the trained model for each fold + the parameters of data normalization
    model_name: "CNN_mdl" # The architecture name
    data_norm_by: "mat" # normalize the features data by feature across the recs
    score_name: "ADOS" # target score. sa, rrb, ADOS
    norm_method: "standard" # features normalization method. z-norm.
    feats_take: 49 # number of first featuress to take
    num_mats_take: 5 # on how much matrices to run
    k_folds: 5 # number of cross-validation splits
    i_mat: 0 # 0,1,2,...num_mats-1. from which feature matrix to start from
    valid_ratio: 0 # validation ratio from the training set. The validation data is selected from the last samples in the x and y data provided, before shuffling
    GPU_id: 0 #  0 or 1. on which GPU to run.
    gender: 'all' # 0 (=boys), 1 (=girls), 'all' in train set
    module: 'all' # [0,1,2,3] # recordings with spesific modules to choose in train set
    random_state: 1337 # random state of data splits
    
hyper_tune_config:
    calculate: 'tune' # tune, read (from the yaml file), or load (from the ready excel file)
    params_idx: 1 # 1,2,...,n_iters. from which combination to start with
    cv_k: 4 # number of folds to run the search tuning
    n_iters: 100 # number of combinations to check
    statistic: "CCC" #  the metric by which to choose the best combination of parameters
    batch_size: # 2**3 - 2**6
        start: 3
        stop: 7 
    n_epochs:
        start: 10
        stop: 2000
        step: 10
    learn_rate: # 0.00001 - 0.1
        start: -5
        stop: 0
    best_params: # in case where calculate="read".
        batch_size: 
        epochs:
        learn_rate: 